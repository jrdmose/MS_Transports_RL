{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "##########################\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import agent\n",
    "import environment\n",
    "import doubledqn\n",
    "import tools\n",
    "import memory\n",
    "import simulation\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools\n",
    "from keras import optimizers \n",
    "\n",
    "def iter_params(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    vals = kwargs.values()\n",
    "    for instance in itertools.product(*vals):\n",
    "        yield dict(zip(keys, instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling experience replay memory...\n",
      "...done filling replay memory\n",
      "Run single_worker -- running episode 1 / 30\n",
      "Run single_worker -- running episode 2 / 30\n",
      "Run single_worker -- running episode 3 / 30\n",
      "Run single_worker -- running episode 4 / 30\n",
      "Run single_worker -- running episode 5 / 30\n",
      "Run single_worker -- running episode 6 / 30\n",
      "Run single_worker -- running episode 7 / 30\n",
      "Run single_worker -- running episode 8 / 30\n",
      "Run single_worker -- running episode 9 / 30\n",
      "Run single_worker -- running episode 10 / 30\n",
      "Run single_worker -- running episode 11 / 30\n",
      "Run single_worker -- running episode 12 / 30\n",
      "Run single_worker -- running episode 13 / 30\n",
      "Run single_worker -- running episode 14 / 30\n",
      "Run single_worker -- running episode 15 / 30\n",
      "Run single_worker -- running episode 16 / 30\n",
      "Run single_worker -- running episode 17 / 30\n",
      "Run single_worker -- running episode 18 / 30\n",
      "Run single_worker -- running episode 19 / 30\n",
      "Run single_worker -- running episode 20 / 30\n",
      "Run single_worker -- running episode 21 / 30\n",
      "Run single_worker -- running episode 22 / 30\n",
      "Run single_worker -- running episode 23 / 30\n",
      "Run single_worker -- running episode 24 / 30\n",
      "Run single_worker -- running episode 25 / 30\n",
      "Run single_worker -- running episode 26 / 30\n",
      "Run single_worker -- running episode 27 / 30\n",
      "Run single_worker -- running episode 28 / 30\n",
      "Run single_worker -- running episode 29 / 30\n",
      "Run single_worker -- running episode 30 / 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ep_id': 0,\n",
       "  'total_reward': 0,\n",
       "  'episode_length': 536,\n",
       "  'av_delay': 255.3457286432161,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 1,\n",
       "  'total_reward': 20,\n",
       "  'episode_length': 502,\n",
       "  'av_delay': 192.97346514047868,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 2,\n",
       "  'total_reward': 50,\n",
       "  'episode_length': 553,\n",
       "  'av_delay': 244.2392821535394,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 3,\n",
       "  'total_reward': 0,\n",
       "  'episode_length': 550,\n",
       "  'av_delay': 251.04597132970835,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 4,\n",
       "  'total_reward': 20,\n",
       "  'episode_length': 493,\n",
       "  'av_delay': 212.97048524262132,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 5,\n",
       "  'total_reward': 60,\n",
       "  'episode_length': 523,\n",
       "  'av_delay': 238.52964824120602,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 6,\n",
       "  'total_reward': 40,\n",
       "  'episode_length': 514,\n",
       "  'av_delay': 223.32293762575452,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 7,\n",
       "  'total_reward': 20,\n",
       "  'episode_length': 531,\n",
       "  'av_delay': 239.45342254246012,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 8,\n",
       "  'total_reward': 50,\n",
       "  'episode_length': 527,\n",
       "  'av_delay': 237.64188163884674,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 9,\n",
       "  'total_reward': 0,\n",
       "  'episode_length': 495,\n",
       "  'av_delay': 225.68602261048304,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 10,\n",
       "  'total_reward': 50,\n",
       "  'episode_length': 497,\n",
       "  'av_delay': 230.3076131687243,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 11,\n",
       "  'total_reward': 100,\n",
       "  'episode_length': 510,\n",
       "  'av_delay': 203.90885684860967,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 12,\n",
       "  'total_reward': 320,\n",
       "  'episode_length': 487,\n",
       "  'av_delay': 193.1779359430605,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 13,\n",
       "  'total_reward': 130,\n",
       "  'episode_length': 484,\n",
       "  'av_delay': 206.51301684532925,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 14,\n",
       "  'total_reward': 20,\n",
       "  'episode_length': 490,\n",
       "  'av_delay': 205.13938165230613,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 15,\n",
       "  'total_reward': 0,\n",
       "  'episode_length': 484,\n",
       "  'av_delay': 145.41977225672878,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 16,\n",
       "  'total_reward': 170,\n",
       "  'episode_length': 445,\n",
       "  'av_delay': 158.2436098069901,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 17,\n",
       "  'total_reward': 0,\n",
       "  'episode_length': 496,\n",
       "  'av_delay': 211.02463549522372,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 18,\n",
       "  'total_reward': 20,\n",
       "  'episode_length': 481,\n",
       "  'av_delay': 191.22313624678662,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 19,\n",
       "  'total_reward': 20,\n",
       "  'episode_length': 480,\n",
       "  'av_delay': 207.11145510835914,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 20,\n",
       "  'total_reward': 20,\n",
       "  'episode_length': 442,\n",
       "  'av_delay': 149.53443673251468,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 21,\n",
       "  'total_reward': 20,\n",
       "  'episode_length': 458,\n",
       "  'av_delay': 188.0814479638009,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 22,\n",
       "  'total_reward': 230,\n",
       "  'episode_length': 520,\n",
       "  'av_delay': 231.24501992031873,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 23,\n",
       "  'total_reward': 0,\n",
       "  'episode_length': 488,\n",
       "  'av_delay': 203.77205507394186,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 24,\n",
       "  'total_reward': 20,\n",
       "  'episode_length': 488,\n",
       "  'av_delay': 195.3421875,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 25,\n",
       "  'total_reward': 0,\n",
       "  'episode_length': 467,\n",
       "  'av_delay': 166.19616977225672,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 26,\n",
       "  'total_reward': 0,\n",
       "  'episode_length': 476,\n",
       "  'av_delay': 199.55244399185335,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 27,\n",
       "  'total_reward': 150,\n",
       "  'episode_length': 490,\n",
       "  'av_delay': 180.04422110552764,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 28,\n",
       "  'total_reward': 0,\n",
       "  'episode_length': 465,\n",
       "  'av_delay': 177.1327843540916,\n",
       "  'label': 'RL'},\n",
       " {'ep_id': 29,\n",
       "  'total_reward': 0,\n",
       "  'episode_length': 471,\n",
       "  'av_delay': 167.16849451645064,\n",
       "  'label': 'RL'}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ONE RUN\n",
    "#############################################\n",
    "\n",
    "param = { \n",
    "    \n",
    "    \"batch_size\" : 30, # 30,50,60,[70]\n",
    "    \"target_update_freq\" : 5000,#10000], # 10000,20000,30000,[40000]\n",
    "    \"gamma\" : 0.99,# # 0.98,0.99,0.995,[0.999]\n",
    "    \"train_freq\" : 1, # 2,3,4,[5]\n",
    "    \"max_size\" : 100000,#,70000], # 20000,50000,70000,[100000]\n",
    "    \"max_ep_length\" : 2000, # 1000,2000,3000,[4000]\n",
    "    \"policy\" : \"linDecEpsGreedy\",#, \"epsGreedy\"],\n",
    "    \"eps\" : 0.2,#, 0.3, 0.1],\n",
    "    \"delta_time\" : 10,\n",
    "    #\"optimizer\": [optimizers.RMSprop(lr= 0.001), optimizers.Adagrad(), optimizers.Adam()]\n",
    "}\n",
    "\n",
    "sumo_RL = simulation.simulator(\n",
    "                    connection_label = \"single_worker\",\n",
    "                    q_network_type = 'simple',\n",
    "                    target_q_network_type = 'simple',\n",
    "                    gamma = param[\"gamma\"],\n",
    "                    target_update_freq = param[\"target_update_freq\"],\n",
    "                    train_freq = param[\"train_freq\"],\n",
    "                    num_burn_in = 200,\n",
    "                    batch_size = param[\"batch_size\"],\n",
    "                    optimizer = 'adam',\n",
    "                    loss_func = \"mse\",\n",
    "                    max_ep_length = param[\"max_ep_length\"],\n",
    "                    experiment_id = \"Check_output\",\n",
    "                    model_checkpoint = True,\n",
    "                    opt_metric = None,\n",
    "\n",
    "                   # environment parameters\n",
    "                    network = \"simple\", # complex\n",
    "                    net_file = \"simple_cross.net.xml\", # \"complex_cross.net.xml\",\n",
    "                    route_file = \"cross.rou.xml\",\n",
    "                    demand = \"rush\",\n",
    "                    state_shape = (1,15), #(1,11) or (1,29)\n",
    "                    num_actions = 2, # 2 or 4\n",
    "                    use_gui = False,\n",
    "                    delta_time = param[\"delta_time\"],\n",
    "\n",
    "                   # memory parameters\n",
    "                    max_size = param[\"max_size\"],\n",
    "\n",
    "                   # additional parameters\n",
    "\n",
    "                    policy = param[\"policy\"],\n",
    "                    eps = param[\"eps\"],\n",
    "                    num_episodes = 30,\n",
    "                    monitoring = True,\n",
    "                    episode_recording = False,\n",
    "                    hparams = param.keys())\n",
    "\n",
    "sumo_RL.train()\n",
    "# agent.load(\"./logs/First gridsearch/run_144/model_checkpoints/runFirst gridsearch_iter165000.h5\")\n",
    "\n",
    "# agent.ddqn.train(env = agent.env, num_episodes = 100, policy = agent.policy, connection_label = agent.connection_label)\n",
    "\n",
    "#evaluation_results = agent.evaluate(runs=2, use_gui= False)\n",
    "#evaluation_results\n",
    "# data= agent.ddqn.evaluate(env = agent.env, policy = \"greedy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "#Build your model here\n",
    "ann_viz(sumo_RL.ddqn.q_network,filename=\"../network\", title = \" Q network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started process # 1\n",
      "Started process # 2\n",
      "Started process # 3\n",
      "Started process # 4\n",
      "Started process # 5\n",
      "Started process # 6\n",
      "Started process # 7\n",
      "Started process # 8\n",
      "Filling experience replay memory...\n",
      "Filling experience replay memory...\n",
      "Filling experience replay memory...\n",
      "Filling experience replay memory...\n",
      "...done filling replay memory\n",
      "Run 1 -- running episode 1 / 10\n",
      "...done filling replay memory\n",
      "Run 4 -- running episode 1 / 10\n",
      "...done filling replay memory\n",
      "Run 3 -- running episode 1 / 10\n",
      "...done filling replay memory\n",
      "Run 2 -- running episode 1 / 10\n",
      "fixed\n",
      "fixed\n",
      "fixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ca44e637-2dbd-4e16-beae-02318cbd0041/jrd/Documents/3. Institut, Universitat i Cursos/BGSE/4.Third_term/1.Master_Thesis/MS_Transports_RL/Scripts/Simple_Cross/cross_RL/environment.py:309: UserWarning: API change now handles step as floating point seconds\n",
      "  fixed_con.simulationStep(t)\n",
      "/mnt/ca44e637-2dbd-4e16-beae-02318cbd0041/jrd/Documents/3. Institut, Universitat i Cursos/BGSE/4.Third_term/1.Master_Thesis/MS_Transports_RL/Scripts/Simple_Cross/cross_RL/environment.py:309: UserWarning: API change now handles step as floating point seconds\n",
      "  fixed_con.simulationStep(t)\n",
      "/mnt/ca44e637-2dbd-4e16-beae-02318cbd0041/jrd/Documents/3. Institut, Universitat i Cursos/BGSE/4.Third_term/1.Master_Thesis/MS_Transports_RL/Scripts/Simple_Cross/cross_RL/environment.py:309: UserWarning: API change now handles step as floating point seconds\n",
      "  fixed_con.simulationStep(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ca44e637-2dbd-4e16-beae-02318cbd0041/jrd/Documents/3. Institut, Universitat i Cursos/BGSE/4.Third_term/1.Master_Thesis/MS_Transports_RL/Scripts/Simple_Cross/cross_RL/environment.py:309: UserWarning: API change now handles step as floating point seconds\n",
      "  fixed_con.simulationStep(t)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 -- running episode 2 / 10\n",
      "Run 3 -- running episode 2 / 10\n",
      "Run 4 -- running episode 2 / 10\n",
      "Run 2 -- running episode 2 / 10\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Run 1 -- running episode 3 / 10\n",
      "Run 3 -- running episode 3 / 10\n",
      "Run 4 -- running episode 3 / 10\n",
      "Run 2 -- running episode 3 / 10\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Run 1 -- running episode 4 / 10\n",
      "Run 3 -- running episode 4 / 10\n",
      "Run 4 -- running episode 4 / 10\n",
      "Run 2 -- running episode 4 / 10\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Run 1 -- running episode 5 / 10\n",
      "Run 4 -- running episode 5 / 10\n",
      "Run 3 -- running episode 5 / 10\n",
      "Run 2 -- running episode 5 / 10\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Run 1 -- running episode 6 / 10\n",
      "Run 3 -- running episode 6 / 10\n",
      "Run 4 -- running episode 6 / 10\n",
      "Run 2 -- running episode 6 / 10\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Run 1 -- running episode 7 / 10\n",
      "Run 2 -- running episode 7 / 10\n",
      "Run 4 -- running episode 7 / 10\n",
      "Run 3 -- running episode 7 / 10\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Run 1 -- running episode 8 / 10\n",
      "Run 3 -- running episode 8 / 10\n",
      "Run 4 -- running episode 8 / 10\n",
      "Run 2 -- running episode 8 / 10\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Run 1 -- running episode 9 / 10\n",
      "Run 3 -- running episode 9 / 10\n",
      "Run 4 -- running episode 9 / 10\n",
      "Run 2 -- running episode 9 / 10\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Run 1 -- running episode 10 / 10\n",
      "fixed\n",
      "Run 2 -- running episode 10 / 10\n",
      "Run 4 -- running episode 10 / 10\n",
      "Run 3 -- running episode 10 / 10\n",
      "fixed\n",
      "Evaluate 1 -- running episode 1 / 5\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Evaluate 2 -- running episode 1 / 5\n",
      "Evaluate 3 -- running episode 1 / 5\n",
      "Evaluate 4 -- running episode 1 / 5\n",
      "fixed\n",
      "Evaluate 1 -- running episode 2 / 5\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Evaluate 2 -- running episode 2 / 5\n",
      "Evaluate 4 -- running episode 2 / 5\n",
      "Evaluate 3 -- running episode 2 / 5\n",
      "fixed\n",
      "Evaluate 1 -- running episode 3 / 5\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Evaluate 2 -- running episode 3 / 5\n",
      "Evaluate 4 -- running episode 3 / 5\n",
      "Evaluate 3 -- running episode 3 / 5\n",
      "fixed\n",
      "Evaluate 1 -- running episode 4 / 5\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Evaluate 2 -- running episode 4 / 5\n",
      "Evaluate 4 -- running episode 4 / 5\n",
      "Evaluate 3 -- running episode 4 / 5\n",
      "fixed\n",
      "Evaluate 1 -- running episode 5 / 5\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "Evaluate 2 -- running episode 5 / 5\n",
      "Evaluate 4 -- running episode 5 / 5\n",
      "Evaluate 3 -- running episode 5 / 5\n",
      "fixed\n",
      "fixed\n",
      "fixed\n",
      "fixed\n"
     ]
    }
   ],
   "source": [
    "# GRIDSEARCH\n",
    "###############################################################\n",
    "\n",
    "experiment_id = \"Test_train_data\" \n",
    "\n",
    "\n",
    "param = { \n",
    "    \n",
    "    \"batch_size\" : [30], #,50],#,50],# 30,50,60,[70]\n",
    "    \"target_update_freq\" : [5000],#,40000],# 100000],  #10000], # 10000,20000,30000,[40000]\n",
    "    \"gamma\" : [0.99],#,0.95],# # 0.98,0.99,0.995,[0.999]\n",
    "    \"train_freq\" : [1],#,4], # 2,3,4,[5]\n",
    "    \"max_size\" : [10000],#,70000], # 20000,50000,70000,[100000]\n",
    "    \"max_ep_length\" : [1000],\n",
    "    \"policy\" : [\"epsGreedy\"],# \"linDecEpsGreedy\"],#, \"epsGreedy\"],\n",
    "    \"eps\" : [0.4],#, 0.3, 0.1],\n",
    "    \"delta_time\" : [10,10,10,10],#,10,10,10,10,10,10,10],\n",
    "    \"reward\" : [\"balanced\"]#,\"negative\"]\n",
    "    #\"optimizer\": [optimizers.RMSprop(lr= 0.001), optimizers.Adagrad(), optimizers.Adam()]\n",
    "}\n",
    "\n",
    "param_grid = iter_params(**param)\n",
    "\n",
    "\n",
    "\n",
    "def worker(input, output):\n",
    "    \"\"\"Runs through a chunk of the grid\"\"\"\n",
    "\n",
    "    for position, args in iter(input.get, 'STOP'):\n",
    "        result = worker_task(position, args)\n",
    "        output.put(result)\n",
    "\n",
    "\n",
    "def worker_task(position, args):\n",
    "    \"\"\"Tells the worker what to do with grid chunk\"\"\"\n",
    "    # initialise all obje\n",
    "    \n",
    "    # print('Run', position + 1, '-- parameters', args)\n",
    "    \n",
    "    sumo_RL = simulation.simulator(\n",
    "                    connection_label = position + 1,\n",
    "                    q_network_type = 'simple',\n",
    "                    target_q_network_type = 'simple',\n",
    "                    gamma = args[\"gamma\"],\n",
    "                    target_update_freq = args[\"target_update_freq\"],\n",
    "                    train_freq = args[\"train_freq\"],\n",
    "                    num_burn_in = 1000,\n",
    "                    batch_size = args[\"batch_size\"],\n",
    "                    optimizer = 'adam',\n",
    "                    loss_func = \"mse\",\n",
    "                    max_ep_length = args[\"max_ep_length\"],\n",
    "                    experiment_id = experiment_id,\n",
    "                    model_checkpoint = True,\n",
    "                    opt_metric = None,\n",
    "\n",
    "                   # environment parameters\n",
    "                    network = \"simple\", # complex\n",
    "                    net_file = \"simple_cross.net.xml\", # \"complex_cross.net.xml\",\n",
    "                    route_file = \"cross.rou.xml\",\n",
    "                    demand = \"rush\",\n",
    "                    state_shape = (1,15),#(1,41)\n",
    "                    num_actions = 2, #4 \n",
    "                    use_gui = False,\n",
    "                    delta_time = args[\"delta_time\"],\n",
    "                    reward = args[\"reward\"],\n",
    "\n",
    "                   # memory parameters\n",
    "                    max_size = args[\"max_size\"],\n",
    "\n",
    "                   # additional parameters\n",
    "\n",
    "                    policy = args[\"policy\"],\n",
    "                    eps = args[\"eps\"],\n",
    "                    num_episodes = 10,\n",
    "                    monitoring = True,\n",
    "                    episode_recording = False,\n",
    "                    eval_fixed = True,\n",
    "                    hparams = args.keys())\n",
    "    \n",
    "    \n",
    "    # print(\"training agent\", position + 1)\n",
    "    train_data = sumo_RL.train()\n",
    "    # print(\"evaluating agent\", position + 1)\n",
    "    evaluation_results = sumo_RL.evaluate(runs = 5)\n",
    "\n",
    "    return ({\"run\" : position + 1,\n",
    "             \"args\" : args, \n",
    "             \"eval_delay\" : evaluation_results, \n",
    "             \"eval_mean_delay\" : evaluation_results[\"average_delay\"],\n",
    "             \"train_data\": train_data})\n",
    "\n",
    "\n",
    "def gridsearch(param_grid):\n",
    "    \"\"\"Runs a parallelised gridsearch\"\"\"\n",
    "\n",
    "    number_of_processes = multiprocessing.cpu_count()\n",
    "\n",
    "    # Set up task list\n",
    "    tasks = [(idx, val) for idx, val in enumerate(param_grid)]\n",
    "\n",
    "    # Create queues\n",
    "    task_queue = multiprocessing.Queue()\n",
    "    done_queue = multiprocessing.Queue()\n",
    "\n",
    "    # Submit tasks\n",
    "    for task in tasks:\n",
    "        task_queue.put(task)\n",
    "    # Start worker processes\n",
    "    for i in range(number_of_processes):\n",
    "        print('Started process #', i + 1)\n",
    "        multiprocessing.Process(target = worker,\n",
    "                                args = (task_queue, done_queue)).start()\n",
    "                    \n",
    "    with open(os.path.join(\"./logs\",experiment_id,\"GS_results.json\"), \"a\") as file:\n",
    "            file.write('{ \"results\": [')\n",
    "      \n",
    "    # Get and print results\n",
    "    results = []\n",
    "    for i in range(len(tasks)):\n",
    "        results.append(done_queue.get())\n",
    "        \n",
    "        with open(os.path.join(\"./logs\",experiment_id,\"GS_results.json\"), \"a\") as file:\n",
    "            json.dump(results[-1], file , indent=4) \n",
    "            if i != len(tasks)-1:\n",
    "                file.write(\",\\n\")\n",
    "            \n",
    "    with open(os.path.join(\"./logs\",experiment_id,\"GS_results.json\"), \"a\") as file:\n",
    "        file.write(\"]}\")\n",
    "                  \n",
    "        #print('%s -- [RESULTS]: Run %s -- Parameters %s -- Mean duration %6.0f' % results[-1])\n",
    "        \n",
    "    # Tell child processes to stop\n",
    "    for i in range(number_of_processes):\n",
    "        task_queue.put('STOP')\n",
    "\n",
    "    # Now combine the results\n",
    "#     scores = [result[-1] for result in results]\n",
    "#     lowest = min(scores)\n",
    "#     winner = results[scores.index(lowest)]\n",
    "#    return winner, results\n",
    "\n",
    "multiprocessing.freeze_support()\n",
    "gridsearch(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_eps = \n",
    "total_it = 100\n",
    "for itr in range(100)\n",
    "    if itr < total_it:\n",
    "        curr_eps = (curr_eps - init_eps) / total_it * itr + init_eps\n",
    "    else :\n",
    "        curr_eps = init_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_test = []\n",
    "eps_test = 0.8\n",
    "for i in range(300000):\n",
    "    eps_test *= omega_test ** i\n",
    "    decay_test.append(eps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(300000),decay_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_results = pd.DataFrame(results).sort_values(by = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max evaluate results\n",
    "\n",
    "res = {}\n",
    "with open('./logs/Test_evaluate/GS_results.json') as file:\n",
    "    data = json.load(file)\n",
    "    for run in data['results']:\n",
    "        run_no = run[\"run\"]\n",
    "        res[f\"{run_no}\"] = run[\"eval_mean_delay\"]\n",
    "        \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json('./logs/Test_evaluate/GS_results.json',)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
