{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "##########################\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import agent\n",
    "import environment\n",
    "import doubledqn\n",
    "import tools\n",
    "import memory\n",
    "import simulation\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools\n",
    "from keras import optimizers \n",
    "\n",
    "def iter_params(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    vals = kwargs.values()\n",
    "    for instance in itertools.product(*vals):\n",
    "        yield dict(zip(keys, instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# ONE RUN\n",
    "#############################################\n",
    "\n",
    "param = { \n",
    "    \n",
    "    \"batch_size\" : 30, # 30,50,60,[70]\n",
    "    \"target_update_freq\" : 5000,#10000], # 10000,20000,30000,[40000]\n",
    "    \"gamma\" : 0.99,# # 0.98,0.99,0.995,[0.999]\n",
    "    \"train_freq\" : 1, # 2,3,4,[5]\n",
    "    \"max_size\" : 100000,#,70000], # 20000,50000,70000,[100000]\n",
    "    \"max_ep_length\" : 2000, # 1000,2000,3000,[4000]\n",
    "    \"policy\" : \"linDecEpsGreedy\",#, \"epsGreedy\"],\n",
    "    \"eps\" : 0.2,#, 0.3, 0.1],\n",
    "    \"delta_time\" : 10,\n",
    "    #\"optimizer\": [optimizers.RMSprop(lr= 0.001), optimizers.Adagrad(), optimizers.Adam()]\n",
    "}\n",
    "\n",
    "sumo_RL = simulation.simulator(\n",
    "                    connection_label = \"single_worker\",\n",
    "                    q_network_type = 'simple',\n",
    "                    target_q_network_type = 'simple',\n",
    "                    gamma = param[\"gamma\"],\n",
    "                    target_update_freq = param[\"target_update_freq\"],\n",
    "                    train_freq = param[\"train_freq\"],\n",
    "                    num_burn_in = 200,\n",
    "                    batch_size = param[\"batch_size\"],\n",
    "                    optimizer = 'adam',\n",
    "                    loss_func = \"mse\",\n",
    "                    max_ep_length = param[\"max_ep_length\"],\n",
    "                    experiment_id = \"Check_output\",\n",
    "                    model_checkpoint = True,\n",
    "                    opt_metric = None,\n",
    "\n",
    "                   # environment parameters\n",
    "                    network = \"simple\", # complex\n",
    "                    net_file = \"simple_cross.net.xml\", # \"complex_cross.net.xml\",\n",
    "                    route_file = \"cross.rou.xml\",\n",
    "                    demand = \"rush\",\n",
    "                    state_shape = (1,15), #(1,11) or (1,29)\n",
    "                    num_actions = 2, # 2 or 4\n",
    "                    use_gui = False,\n",
    "                    delta_time = param[\"delta_time\"],\n",
    "\n",
    "                   # memory parameters\n",
    "                    max_size = param[\"max_size\"],\n",
    "\n",
    "                   # additional parameters\n",
    "\n",
    "                    policy = param[\"policy\"],\n",
    "                    eps = param[\"eps\"],\n",
    "                    num_episodes = 30,\n",
    "                    monitoring = True,\n",
    "                    episode_recording = False,\n",
    "                    hparams = param.keys())\n",
    "\n",
    "sumo_RL.train()\n",
    "# agent.load(\"./logs/First gridsearch/run_144/model_checkpoints/runFirst gridsearch_iter165000.h5\")\n",
    "\n",
    "# agent.ddqn.train(env = agent.env, num_episodes = 100, policy = agent.policy, connection_label = agent.connection_label)\n",
    "\n",
    "#evaluation_results = agent.evaluate(runs=2, use_gui= False)\n",
    "#evaluation_results\n",
    "# data= agent.ddqn.evaluate(env = agent.env, policy = \"greedy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ann_visualizer.visualize import ann_viz;\n",
    "#Build your model here\n",
    "ann_viz(sumo_RL.ddqn.q_network,filename=\"../network\", title = \" Q network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GRIDSEARCH\n",
    "###############################################################\n",
    "\n",
    "experiment_id = \"Balanced_Negative_Policy\" \n",
    "\n",
    "\n",
    "param = { \n",
    "    \n",
    "    \"batch_size\" : [30], #,50],#,50],# 30,50,60,[70]\n",
    "    \"target_update_freq\" : [5000,10000],#,40000],# 100000],  #10000], # 10000,20000,30000,[40000]\n",
    "    \"gamma\" : [0.99],#,0.95],# # 0.98,0.99,0.995,[0.999]\n",
    "    \"train_freq\" : [1],#,4], # 2,3,4,[5]\n",
    "    \"max_size\" : [10000],#,70000], # 20000,50000,70000,[100000]\n",
    "    \"max_ep_length\" : [1000],\n",
    "    \"policy\" : [\"epsGreedy\",\"linDecEpsGreedy\"],#, \"epsGreedy\"],\n",
    "    \"eps\" : [0.2, 0.1, 0.05],\n",
    "    \"delta_time\" : [10],#,10,10,10],#,10,10,10,10,10,10,10],\n",
    "    \"reward\" : [\"balanced\",\"negative\"]\n",
    "    #\"optimizer\": [optimizers.RMSprop(lr= 0.001), optimizers.Adagrad(), optimizers.Adam()]\n",
    "}\n",
    "\n",
    "param_grid = iter_params(**param)\n",
    "\n",
    "\n",
    "\n",
    "def worker(input, output):\n",
    "    \"\"\"Runs through a chunk of the grid\"\"\"\n",
    "\n",
    "    for position, args in iter(input.get, 'STOP'):\n",
    "        result = worker_task(position, args)\n",
    "        output.put(result)\n",
    "\n",
    "\n",
    "def worker_task(position, args):\n",
    "    \"\"\"Tells the worker what to do with grid chunk\"\"\"\n",
    "    # initialise all obje\n",
    "    \n",
    "    # print('Run', position + 1, '-- parameters', args)\n",
    "    \n",
    "    sumo_RL = simulation.simulator(\n",
    "                    connection_label = position + 1,\n",
    "                    q_network_type = 'simple',\n",
    "                    target_q_network_type = 'simple',\n",
    "                    gamma = args[\"gamma\"],\n",
    "                    target_update_freq = args[\"target_update_freq\"],\n",
    "                    train_freq = args[\"train_freq\"],\n",
    "                    num_burn_in = 1000,\n",
    "                    batch_size = args[\"batch_size\"],\n",
    "                    optimizer = 'adam',\n",
    "                    loss_func = \"mse\",\n",
    "                    max_ep_length = args[\"max_ep_length\"],\n",
    "                    experiment_id = experiment_id,\n",
    "                    model_checkpoint = True,\n",
    "                    opt_metric = None,\n",
    "\n",
    "                   # environment parameters\n",
    "                    network = \"simple\", # complex\n",
    "                    net_file = \"simple_cross.net.xml\", # \"complex_cross.net.xml\",\n",
    "                    route_file = \"cross.rou.xml\",\n",
    "                    demand = \"rush\",\n",
    "                    state_shape = (1,15),#(1,41)\n",
    "                    num_actions = 2, #4 \n",
    "                    use_gui = False,\n",
    "                    delta_time = args[\"delta_time\"],\n",
    "                    reward = args[\"reward\"],\n",
    "\n",
    "                   # memory parameters\n",
    "                    max_size = args[\"max_size\"],\n",
    "\n",
    "                   # additional parameters\n",
    "\n",
    "                    policy = args[\"policy\"],\n",
    "                    eps = args[\"eps\"],\n",
    "                    num_episodes = 10,\n",
    "                    monitoring = True,\n",
    "                    episode_recording = False,\n",
    "                    eval_fixed = True,\n",
    "                    hparams = args.keys())\n",
    "    \n",
    "    \n",
    "    # print(\"training agent\", position + 1)\n",
    "    train_data = sumo_RL.train()\n",
    "    # print(\"evaluating agent\", position + 1)\n",
    "    evaluation_results = sumo_RL.evaluate(runs = 5)\n",
    "\n",
    "    return ({\"run\" : position + 1,\n",
    "             \"args\" : args, \n",
    "             \"eval_delay\" : evaluation_results, \n",
    "             \"eval_mean_delay\" : evaluation_results[\"average_delay\"],\n",
    "             \"train_data\": train_data})\n",
    "\n",
    "\n",
    "def gridsearch(param_grid):\n",
    "    \"\"\"Runs a parallelised gridsearch\"\"\"\n",
    "\n",
    "    number_of_processes = multiprocessing.cpu_count()\n",
    "\n",
    "    # Set up task list\n",
    "    tasks = [(idx, val) for idx, val in enumerate(param_grid)]\n",
    "\n",
    "    # Create queues\n",
    "    task_queue = multiprocessing.Queue()\n",
    "    done_queue = multiprocessing.Queue()\n",
    "\n",
    "    # Submit tasks\n",
    "    for task in tasks:\n",
    "        task_queue.put(task)\n",
    "    # Start worker processes\n",
    "    for i in range(number_of_processes):\n",
    "        print('Started process #', i + 1)\n",
    "        multiprocessing.Process(target = worker,\n",
    "                                args = (task_queue, done_queue)).start()\n",
    "                    \n",
    "    with open(os.path.join(\"./logs\",experiment_id,\"GS_results.json\"), \"a\") as file:\n",
    "            file.write('{ \"results\": [')\n",
    "      \n",
    "    # Get and print results\n",
    "    results = []\n",
    "    for i in range(len(tasks)):\n",
    "        results.append(done_queue.get())\n",
    "        \n",
    "        with open(os.path.join(\"./logs\",experiment_id,\"GS_results.json\"), \"a\") as file:\n",
    "            json.dump(results[-1], file , indent=4) \n",
    "            if i != len(tasks)-1:\n",
    "                file.write(\",\\n\")\n",
    "            \n",
    "    with open(os.path.join(\"./logs\",experiment_id,\"GS_results.json\"), \"a\") as file:\n",
    "        file.write(\"]}\")\n",
    "                  \n",
    "        #print('%s -- [RESULTS]: Run %s -- Parameters %s -- Mean duration %6.0f' % results[-1])\n",
    "        \n",
    "    # Tell child processes to stop\n",
    "    for i in range(number_of_processes):\n",
    "        task_queue.put('STOP')\n",
    "\n",
    "    # Now combine the results\n",
    "#     scores = [result[-1] for result in results]\n",
    "#     lowest = min(scores)\n",
    "#     winner = results[scores.index(lowest)]\n",
    "#    return winner, results\n",
    "\n",
    "multiprocessing.freeze_support()\n",
    "gridsearch(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_eps = \n",
    "total_it = 100\n",
    "for itr in range(100)\n",
    "    if itr < total_it:\n",
    "        curr_eps = (curr_eps - init_eps) / total_it * itr + init_eps\n",
    "    else :\n",
    "        curr_eps = init_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_test = []\n",
    "eps_test = 0.8\n",
    "for i in range(300000):\n",
    "    eps_test *= omega_test ** i\n",
    "    decay_test.append(eps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(300000),decay_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_results = pd.DataFrame(results).sort_values(by = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max evaluate results\n",
    "\n",
    "res = {}\n",
    "with open('./logs/Test_evaluate/GS_results.json') as file:\n",
    "    data = json.load(file)\n",
    "    for run in data['results']:\n",
    "        run_no = run[\"run\"]\n",
    "        res[f\"{run_no}\"] = run[\"eval_mean_delay\"]\n",
    "        \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json('./logs/Test_evaluate/GS_results.json',)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
