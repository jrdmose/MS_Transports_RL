{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep reinforcement learning for the optimization of traffic light control with real-time data: \n",
    "\n",
    "## Hyperparameter gridsearch\n",
    "\n",
    "\n",
    "### Instructions for running\n",
    "\n",
    "Below you can find the description of the parameters you can use for the simulation class or wrapper for training a DDQN in a preset SUMO environment.\n",
    "\n",
    "Also, you can find a self-explanatory example of how to run a gridsearch for algorithm hyperparams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "#### DDQN parameters\n",
    "\n",
    "**q_network** : (str) keras model instance to predict q-values for current state ('simple' or 'linear')\n",
    "\n",
    "**gamma** : (int) discount factor for rewards\n",
    "\n",
    "**target_update_freq** : (int) defines after how many steps the q-network should be re-trained\n",
    "\n",
    "**train_freq**: (int) How often you actually update your Q-Network. Sometimes stability is improved\n",
    "    if you collect a couple samples for your replay memory, for every Q-network update that you run.\n",
    "\n",
    "**num_burn_in** : (int) defines the size of the replay memory to be filled before, using a specified policy\n",
    "\n",
    "**batch_size** : (int) size of batches to be used to train models\n",
    "\n",
    "**optimizer** : (str) keras optimizer identifier ('adam')\n",
    "\n",
    "**max_ep_len** : (int) stops simulation after specified number of episodes\n",
    "\n",
    "**experiment_id** : (str) ID of simulation\n",
    "\n",
    "**model_checkpoint** : (bool) store keras model checkpoints during training\n",
    "\n",
    "**policy** : (str) policy to choose actions ('epsGredy', 'linDecEpsGreedy', 'greedy' 'randUni')\n",
    "\n",
    "**eps** : (float) exploration factor\n",
    "    if policy = 'linDecEpsGreedy' -> The epsilon will decay from 1 to eps\n",
    "    if policy = 'epsGredy' -> eps to evaluate eps policy\n",
    "    \n",
    "\n",
    "\n",
    "#### Environment parameters\n",
    "\n",
    "**network** : (str) network complexity ('simple' or 'complex')\n",
    "\n",
    "**demand**: (str) demand scenario ('rush' or 'nominal')\n",
    "\n",
    "**use_gui** : (bool) wether to use user interface\n",
    "\n",
    "**delta_time** : (int) simulation time between actions\n",
    "\n",
    "**reward** : type of reward. ('balanced' or 'negative')\n",
    "\n",
    "#### Memory buffer parameters\n",
    "\n",
    " \n",
    "**max_size** : (int) memory capacity required\n",
    "\n",
    "#### Additional parameters\n",
    "\n",
    "\n",
    "**num_episodes** : (int) number of episodes to train the algorithm. THis can also be changed in train method.\n",
    "\n",
    "**eval_fixed** = (bool) Evaluate fixed policy during training. Used for plotting\n",
    "\n",
    "**monitoring** : (bool) store episode logs in tensorboard\n",
    "\n",
    "**episode_recording** : (bool) store intra episode logs in tensorboard\n",
    "\n",
    "**seed** = (int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "##########################\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "\n",
    "import simulation\n",
    "import plotting\n",
    "import tools\n",
    "import glob\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "# import tensorflow as tf\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    \n",
    "    \"experiment_id\" : [\"Test_gridsearch\"],\n",
    "    \"batch_size\" : [30,50],\n",
    "    \"target_update_freq\" : [5000,10000],\n",
    "    \"gamma\" : [0.99],\n",
    "    \"train_freq\" : [1],\n",
    "    \"max_size\" : [10000],\n",
    "    \"max_ep_length\" : [1000],\n",
    "    \"policy\" : [\"epsGreedy\",\"linDecEpsGreedy\"],\n",
    "    \"eps\" : [0.1],\n",
    "    \"delta_time\" : [10],\n",
    "    \"reward\" : [\"balanced\"],\n",
    "    \"network\" : [\"simple\"],\n",
    "    \"num_episodes\" : [50],\n",
    "}\n",
    "\n",
    "log_path = \"./logs/\"+ param[\"experiment_id\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = tools.iter_params(**param)\n",
    "tools.gridsearch(list(param_grid), log_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monitoring progress in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In your terminal \n",
    "#tensorboard --logdir='./Scripts/logs' #Change relative path if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting best performer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max evaluate results\n",
    "res = tools.get_grid_search_results(log_path)\n",
    "res.sort_values(\"RL_mean_delay\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading last checkpoint of selected performer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 1 # selected run\n",
    "sumo_RL = tools.load_last_model_checkpoint(log_path, run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate using user interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sumo_RL.evaluate(runs=1, use_gui=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
