{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/seb/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "##########################\n",
    "\n",
    "import agent\n",
    "import environment\n",
    "import doubledqn\n",
    "import tools\n",
    "import memory\n",
    "import simulation\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools\n",
    "from keras import optimizers \n",
    "\n",
    "def iter_params(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    vals = kwargs.values()\n",
    "    for instance in itertools.product(*vals):\n",
    "        yield instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE RUN\n",
    "#############################################\n",
    "\n",
    "agent = simulation.simulator(\n",
    "                     connection_label = \"lonely_worker\",\n",
    "                     q_network_type = 'simple',\n",
    "                     target_q_network_type = 'simple',\n",
    "                     gamma = 0.99,\n",
    "                     target_update_freq = 10000,\n",
    "                     train_freq = 3,\n",
    "                     num_burn_in = 300,\n",
    "                     batch_size = 32,\n",
    "                     optimizer = optimizers.RMSprop(lr=0.001, rho=0.95),\n",
    "                     loss_func = \"mse\",\n",
    "                     max_ep_length = 1000,\n",
    "                     experiment_id = \"Exp_1\",\n",
    "                     model_checkpoint = True,\n",
    "                     opt_metric = None,\n",
    "                     \n",
    "                    # environment parameters\n",
    "                     net_file = \"cross.net.xml\",\n",
    "                     route_file = \"cross.rou.xml\",\n",
    "                     state_shape = (1,11),\n",
    "                     num_actions = 2,\n",
    "                     use_gui = False,\n",
    "                     delta_time = 10,\n",
    "                 \n",
    "                    # memory parameters\n",
    "                     max_size = 100000,\n",
    "                 \n",
    "                    # additional parameters\n",
    "                 \n",
    "                     policy = \"linDecEpsGreedy\",\n",
    "                     eps = 0.1,\n",
    "                     num_episodes = 2,\n",
    "                     monitoring = True)\n",
    "agent.train()\n",
    "# agent.load(\"./logs/First gridsearch/run_144/model_checkpoints/runFirst gridsearch_iter165000.h5\")\n",
    "# agent.evaluate(runs=1, use_gui= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started process # 1\n",
      "Started process # 2\n",
      "Started process # 3\n",
      "Started process # 4\n",
      "Started process # 5\n",
      "Started process # 6\n",
      "Started process # 7\n",
      "Started process # 8\n",
      "Run 3 -- running episode 1 / 30\n",
      "Run 1 -- running episode 1 / 30\n",
      "Run 5 -- running episode 1 / 30\n",
      "Run 7 -- running episode 1 / 30\n",
      "Run 6 -- running episode 1 / 30\n",
      "Run 4 -- running episode 1 / 30\n",
      "Run 8 -- running episode 1 / 30\n",
      "Run 2 -- running episode 1 / 30\n",
      "Run 1 -- running episode 11 / 30\n",
      "Run 5 -- running episode 11 / 30\n",
      "Run 7 -- running episode 11 / 30\n",
      "Run 3 -- running episode 11 / 30\n",
      "Run 8 -- running episode 11 / 30\n",
      "Run 4 -- running episode 11 / 30\n",
      "Run 6 -- running episode 11 / 30\n",
      "Run 2 -- running episode 11 / 30\n",
      "Run 1 -- running episode 21 / 30\n",
      "Run 7 -- running episode 21 / 30\n",
      "Run 5 -- running episode 21 / 30\n",
      "Run 3 -- running episode 21 / 30\n",
      "Run 8 -- running episode 21 / 30\n",
      "Run 6 -- running episode 21 / 30\n",
      "Run 2 -- running episode 21 / 30\n",
      "Run 4 -- running episode 21 / 30\n",
      "Process-23 -- [RESULTS]: Run 7 -- Parameters (40, 10000, 0.995, 4, 50000) -- Mean duration  12111\n",
      "Process-18 -- [RESULTS]: Run 2 -- Parameters (40, 8000, 0.99, 4, 100000) -- Mean duration  12054\n",
      "Process-17 -- [RESULTS]: Run 1 -- Parameters (40, 8000, 0.99, 4, 50000) -- Mean duration  12206\n",
      "Process-20 -- [RESULTS]: Run 4 -- Parameters (40, 8000, 0.995, 4, 100000) -- Mean duration  12208\n",
      "Run 9 -- running episode 1 / 30\n",
      "Run 10 -- running episode 1 / 30\n",
      "Process-24 -- [RESULTS]: Run 8 -- Parameters (40, 10000, 0.995, 4, 100000) -- Mean duration  12392\n",
      "Run 11 -- running episode 1 / 30\n",
      "Run 12 -- running episode 1 / 30\n",
      "Run 13 -- running episode 1 / 30\n",
      "Process-19 -- [RESULTS]: Run 3 -- Parameters (40, 8000, 0.995, 4, 50000) -- Mean duration  12568\n",
      "Run 14 -- running episode 1 / 30\n",
      "Process-22 -- [RESULTS]: Run 6 -- Parameters (40, 10000, 0.99, 4, 100000) -- Mean duration  12538\n",
      "Run 15 -- running episode 1 / 30\n",
      "Process-21 -- [RESULTS]: Run 5 -- Parameters (40, 10000, 0.99, 4, 50000) -- Mean duration  12686\n",
      "Run 16 -- running episode 1 / 30\n",
      "Run 12 -- running episode 11 / 30\n",
      "Run 13 -- running episode 11 / 30\n",
      "Run 15 -- running episode 11 / 30\n",
      "Run 9 -- running episode 11 / 30\n",
      "Run 11 -- running episode 11 / 30\n",
      "Run 10 -- running episode 11 / 30\n",
      "Run 14 -- running episode 11 / 30\n",
      "Run 15 -- running episode 21 / 30\n",
      "Run 13 -- running episode 21 / 30\n",
      "Run 12 -- running episode 21 / 30\n",
      "Run 16 -- running episode 11 / 30\n",
      "Run 9 -- running episode 21 / 30\n",
      "Run 11 -- running episode 21 / 30\n",
      "Run 10 -- running episode 21 / 30\n",
      "Run 14 -- running episode 21 / 30\n",
      "Process-22 -- [RESULTS]: Run 15 -- Parameters (50, 10000, 0.995, 4, 50000) -- Mean duration    104\n",
      "Run 16 -- running episode 21 / 30\n",
      "Process-23 -- [RESULTS]: Run 9 -- Parameters (50, 8000, 0.99, 4, 50000) -- Mean duration   1335\n",
      "Process-18 -- [RESULTS]: Run 10 -- Parameters (50, 8000, 0.99, 4, 100000) -- Mean duration   1062\n",
      "Process-24 -- [RESULTS]: Run 13 -- Parameters (50, 10000, 0.99, 4, 50000) -- Mean duration   9068\n",
      "Process-19 -- [RESULTS]: Run 14 -- Parameters (50, 10000, 0.99, 4, 100000) -- Mean duration   1142\n",
      "Process-20 -- [RESULTS]: Run 12 -- Parameters (50, 8000, 0.995, 4, 100000) -- Mean duration   4450\n",
      "Process-17 -- [RESULTS]: Run 11 -- Parameters (50, 8000, 0.995, 4, 50000) -- Mean duration  11021\n",
      "Process-21 -- [RESULTS]: Run 16 -- Parameters (50, 10000, 0.995, 4, 100000) -- Mean duration  12864\n"
     ]
    }
   ],
   "source": [
    "# GRIDSEARCH\n",
    "###############################################################\n",
    "\n",
    "exp_id = \"Seb_GS_long_good_params\"\n",
    "\n",
    "param = {\n",
    "    \"batch_size\" : [40,50,60],\n",
    "    \"target_update_frequency\" : [10000,15000],#, 20000,40000]\n",
    "    \"gamma\" : [0.995,0.999],\n",
    "    \"train_freq\" : [4,5],\n",
    "    \"max_size\" : [50000,100000]\n",
    "}\n",
    "\n",
    "param_grid = iter_params(**param)\n",
    "\n",
    "def worker(input, output):\n",
    "    \"\"\"Runs through a chunk of the grid\"\"\"\n",
    "\n",
    "    for position, args in iter(input.get, 'STOP'):\n",
    "        result = worker_task(position, args)\n",
    "        output.put(result)\n",
    "\n",
    "\n",
    "def worker_task(position, args):\n",
    "    \"\"\"Tells the worker what to do with grid chunk\"\"\"\n",
    "    # initialise all objects\n",
    "    \n",
    "    # print('Run', position + 1, '-- parameters', args)\n",
    "    \n",
    "    agent = simulation.simulator(connection_label = position + 1,\n",
    "                                batch_size = args[0],\n",
    "                                target_update_freq = args[1],\n",
    "                                gamma = args[2],\n",
    "                                train_freq = args[3],\n",
    "                                max_size = args[4],\n",
    "                                monitoring = True,\n",
    "                                num_episodes =  500,\n",
    "                                experiment_id = exp_id)\n",
    "    # print(\"training agent\", position + 1)\n",
    "    \n",
    "    agent.train()\n",
    "    # print(\"evaluating agent\", position + 1)\n",
    "    result = agent.evaluate(runs = 3)\n",
    "\n",
    "    return (multiprocessing.current_process().name, position + 1, args, result)\n",
    "\n",
    "\n",
    "def gridsearch(param_grid):\n",
    "    \"\"\"Runs a parallelised gridsearch\"\"\"\n",
    "\n",
    "    number_of_processes = multiprocessing.cpu_count()\n",
    "\n",
    "    # Set up task list\n",
    "    tasks = [(idx, val) for idx, val in enumerate(param_grid)]\n",
    "\n",
    "    # Create queues\n",
    "    task_queue = multiprocessing.Queue()\n",
    "    done_queue = multiprocessing.Queue()\n",
    "\n",
    "    # Submit tasks\n",
    "    for task in tasks:\n",
    "        task_queue.put(task)\n",
    "    # Start worker processes\n",
    "    for i in range(number_of_processes):\n",
    "        print('Started process #', i + 1)\n",
    "        multiprocessing.Process(target = worker,\n",
    "                                args = (task_queue, done_queue)).start()\n",
    "    \n",
    "    \n",
    "    with open(os.path.join(\"./logs\",exp_id,\"GS_results\"), \"w\",newline='') as file:\n",
    "        writer = csv.writer(file, dialect = 'excel')\n",
    "        writer.writerow([\"Process\", \"Run\", \"Parameters\", \"Result\"])\n",
    "    \n",
    "    # Get and print results\n",
    "    results = []\n",
    "    for i in range(len(tasks)):\n",
    "        results.append(done_queue.get())\n",
    "        with open(os.path.join(\"./logs\",exp_id,\"GS_results\"), \"a\",newline='') as file:\n",
    "            writer = csv.writer(file, dialect = 'excel')\n",
    "            writer.writerow(results[-1])                \n",
    "        print('%s -- [RESULTS]: Run %s -- Parameters %s -- Mean duration %6.0f' % results[-1])\n",
    "        \n",
    "    # Tell child processes to stop\n",
    "    for i in range(number_of_processes):\n",
    "        task_queue.put('STOP')\n",
    "\n",
    "    # Now combine the results\n",
    "    scores = [result[-1] for result in results]\n",
    "    lowest = min(scores)\n",
    "    winner = results[scores.index(lowest)]\n",
    "    return winner, results\n",
    "\n",
    "multiprocessing.freeze_support()\n",
    "winner, results = gridsearch(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Process-22', 15, (50, 10000, 0.995, 4, 50000), 104.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
