{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/seb/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "##########################\n",
    "\n",
    "import agent\n",
    "import environment\n",
    "import doubledqn\n",
    "import tools\n",
    "import memory\n",
    "import simulation\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools\n",
    "from keras import optimizers \n",
    "\n",
    "def iter_params(**kwargs):\n",
    "    keys = kwargs.keys()\n",
    "    vals = kwargs.values()\n",
    "    for instance in itertools.product(*vals):\n",
    "        yield dict(zip(keys, instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ONE RUN\n",
    "#############################################\n",
    "\n",
    "param = { \n",
    "    \n",
    "    \"batch_size\" : 30, # 30,50,60,[70]\n",
    "    \"target_update_freq\" : 10000,#10000], # 10000,20000,30000,[40000]\n",
    "    \"gamma\" : 0.99,# # 0.98,0.99,0.995,[0.999]\n",
    "    \"train_freq\" : 1, # 2,3,4,[5]\n",
    "    \"max_size\" : 100000,#,70000], # 20000,50000,70000,[100000]\n",
    "    \"max_ep_length\" : 2000, # 1000,2000,3000,[4000]\n",
    "    \"policy\" : \"epsGreedy\",#, \"epsGreedy\"],\n",
    "    \"eps\" : 0.1,#, 0.3, 0.1],\n",
    "    \"delta_time\" : 10,\n",
    "    #\"optimizer\": [optimizers.RMSprop(lr= 0.001), optimizers.Adagrad(), optimizers.Adam()]\n",
    "}\n",
    "\n",
    "sumo_RL = simulation.simulator(\n",
    "                    connection_label = \"single_worker\",\n",
    "                    q_network_type = 'simple',\n",
    "                    target_q_network_type = 'simple',\n",
    "                    gamma = param[\"gamma\"],\n",
    "                    target_update_freq = param[\"target_update_freq\"],\n",
    "                    train_freq = param[\"train_freq\"],\n",
    "                    num_burn_in = 1000,\n",
    "                    batch_size = param[\"batch_size\"],\n",
    "                    optimizer = optimizers.RMSprop(lr= 0.001),\n",
    "                    loss_func = \"mse\",\n",
    "                    max_ep_length = param[\"max_ep_length\"],\n",
    "                    experiment_id = \"Testing_Folders\",\n",
    "                    model_checkpoint = True,\n",
    "                    opt_metric = None,\n",
    "\n",
    "                   # environment parameters\n",
    "                    net_file = \"cross.net.xml\",\n",
    "                    route_file = \"cross.rou.xml\",\n",
    "                    demand = \"nominal\",\n",
    "                    state_shape = (1,11),\n",
    "                    num_actions = 2,\n",
    "                    use_gui = False,\n",
    "                    delta_time = param[\"delta_time\"],\n",
    "\n",
    "                   # memory parameters\n",
    "                    max_size = param[\"max_size\"],\n",
    "\n",
    "                   # additional parameters\n",
    "\n",
    "                    policy = param[\"policy\"],\n",
    "                    eps = param[\"eps\"],\n",
    "                    num_episodes = 2,\n",
    "                    monitoring = True,\n",
    "                    episode_recording = False,\n",
    "                    hparams = param.keys())\n",
    "\n",
    "sumo_RL.train()\n",
    "# agent.load(\"./logs/First gridsearch/run_144/model_checkpoints/runFirst gridsearch_iter165000.h5\")\n",
    "\n",
    "# agent.ddqn.train(env = agent.env, num_episodes = 100, policy = agent.policy, connection_label = agent.connection_label)\n",
    "\n",
    "evaluation_results = sumo_RL.evaluate(runs=2, use_gui= False)\n",
    "evaluation_results\n",
    "# data= agent.ddqn.evaluate(env = agent.env, policy = \"greedy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started process # 1\n",
      "Started process # 2\n",
      "Started process # 3\n",
      "Started process # 4\n",
      "Started process # 5\n",
      "Started process # 6\n",
      "Started process # 7\n",
      "Started process # 8\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Run 4 -- running episode 1 / 2\n",
      "Run 1 -- running episode 1 / 2\n",
      "Run 2 -- running episode 1 / 2\n",
      "Run 3 -- running episode 1 / 2\n",
      "Run 5 -- running episode 1 / 2\n",
      "Run 7 -- running episode 1 / 2\n",
      "Run 6 -- running episode 1 / 2\n",
      "Run 8 -- running episode 1 / 2\n",
      "Run 4 -- running episode 2 / 2\n",
      "Run 1 -- running episode 2 / 2\n",
      "Run 2 -- running episode 2 / 2\n",
      "Run 3 -- running episode 2 / 2\n",
      "Run 5 -- running episode 2 / 2\n",
      "Run 7 -- running episode 2 / 2\n",
      "Run 8 -- running episode 2 / 2\n",
      "Run 6 -- running episode 2 / 2\n",
      "Evaluate 4 -- running episode 1 / 5\n",
      "Evaluate 1 -- running episode 1 / 5\n",
      "Evaluate 2 -- running episode 1 / 5\n",
      "Evaluate 7 -- running episode 1 / 5\n",
      "Evaluate 3 -- running episode 1 / 5\n",
      "Evaluate 5 -- running episode 1 / 5\n",
      "Evaluate 8 -- running episode 1 / 5\n",
      "Evaluate 6 -- running episode 1 / 5\n",
      "Evaluate 4 -- running episode 2 / 5\n",
      "Evaluate 1 -- running episode 2 / 5\n",
      "Evaluate 3 -- running episode 2 / 5\n",
      "Evaluate 5 -- running episode 2 / 5\n",
      "Evaluate 6 -- running episode 2 / 5\n",
      "Evaluate 2 -- running episode 2 / 5\n",
      "Evaluate 7 -- running episode 2 / 5\n",
      "Evaluate 8 -- running episode 2 / 5\n",
      "Evaluate 1 -- running episode 3 / 5\n",
      "Evaluate 4 -- running episode 3 / 5\n",
      "Evaluate 3 -- running episode 3 / 5\n",
      "Evaluate 5 -- running episode 3 / 5\n",
      "Evaluate 2 -- running episode 3 / 5\n",
      "Evaluate 7 -- running episode 3 / 5\n",
      "Evaluate 6 -- running episode 3 / 5\n",
      "Evaluate 8 -- running episode 3 / 5\n",
      "Evaluate 1 -- running episode 4 / 5\n",
      "Evaluate 4 -- running episode 4 / 5\n",
      "Evaluate 3 -- running episode 4 / 5\n",
      "Evaluate 2 -- running episode 4 / 5\n",
      "Evaluate 6 -- running episode 4 / 5\n",
      "Evaluate 5 -- running episode 4 / 5\n",
      "Evaluate 7 -- running episode 4 / 5\n",
      "Evaluate 8 -- running episode 4 / 5\n",
      "Evaluate 1 -- running episode 5 / 5\n",
      "Evaluate 4 -- running episode 5 / 5\n",
      "Evaluate 3 -- running episode 5 / 5\n",
      "Evaluate 2 -- running episode 5 / 5\n",
      "Evaluate 6 -- running episode 5 / 5\n",
      "Evaluate 5 -- running episode 5 / 5\n",
      "Evaluate 7 -- running episode 5 / 5\n",
      "Evaluate 8 -- running episode 5 / 5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exp_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-12b29a7913c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m \u001b[0mwinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridsearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0mwinner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-12b29a7913c2>\u001b[0m in \u001b[0;36mgridsearch\u001b[0;34m(param_grid)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./logs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexp_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"GS_results\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"a\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m             \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdialect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'excel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exp_id' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Run 9 -- running episode 1 / 2\n",
      "Run 10 -- running episode 1 / 2\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Episode finished during memory replay fill. Starting new episode...\n",
      "Run 11 -- running episode 1 / 2\n",
      "Run 12 -- running episode 1 / 2\n",
      "Run 13 -- running episode 1 / 2\n",
      "Run 14 -- running episode 1 / 2\n",
      "Run 16 -- running episode 1 / 2\n",
      "Run 15 -- running episode 1 / 2\n",
      "Run 10 -- running episode 2 / 2\n",
      "Run 12 -- running episode 2 / 2\n",
      "Run 13 -- running episode 2 / 2\n",
      "Run 14 -- running episode 2 / 2\n",
      "Run 15 -- running episode 2 / 2\n",
      "Run 11 -- running episode 2 / 2\n",
      "Run 9 -- running episode 2 / 2\n",
      "Run 16 -- running episode 2 / 2\n",
      "Evaluate 10 -- running episode 1 / 5\n",
      "Evaluate 12 -- running episode 1 / 5\n",
      "Evaluate 13 -- running episode 1 / 5\n",
      "Evaluate 14 -- running episode 1 / 5\n",
      "Evaluate 15 -- running episode 1 / 5\n",
      "Evaluate 9 -- running episode 1 / 5\n",
      "Evaluate 16 -- running episode 1 / 5\n",
      "Evaluate 11 -- running episode 1 / 5\n",
      "Evaluate 12 -- running episode 2 / 5\n",
      "Evaluate 10 -- running episode 2 / 5\n",
      "Evaluate 13 -- running episode 2 / 5\n",
      "Evaluate 14 -- running episode 2 / 5\n",
      "Evaluate 15 -- running episode 2 / 5\n",
      "Evaluate 9 -- running episode 2 / 5\n",
      "Evaluate 16 -- running episode 2 / 5\n",
      "Evaluate 11 -- running episode 2 / 5\n",
      "Evaluate 12 -- running episode 3 / 5\n",
      "Evaluate 10 -- running episode 3 / 5\n",
      "Evaluate 13 -- running episode 3 / 5\n",
      "Evaluate 14 -- running episode 3 / 5\n",
      "Evaluate 15 -- running episode 3 / 5\n",
      "Evaluate 9 -- running episode 3 / 5\n",
      "Evaluate 16 -- running episode 3 / 5\n",
      "Evaluate 12 -- running episode 4 / 5\n",
      "Evaluate 11 -- running episode 3 / 5\n"
     ]
    }
   ],
   "source": [
    "# GRIDSEARCH\n",
    "###############################################################\n",
    "\n",
    "experiment_id = \"TEsting arguments_2\" \n",
    "\n",
    "\n",
    "param = { \n",
    "    \n",
    "    \"batch_size\" : [30,100], # 30,50,60,[70]\n",
    "    \"target_update_freq\" : [10000],#10000], # 10000,20000,30000,[40000]\n",
    "    \"gamma\" : [0.99],# # 0.98,0.99,0.995,[0.999]\n",
    "    \"train_freq\" : [1], # 2,3,4,[5]\n",
    "    \"max_size\" : [100000],#,70000], # 20000,50000,70000,[100000]\n",
    "    \"max_ep_length\" : [2000], # 1000,2000,3000,[4000]\n",
    "    \"policy\" : [\"epsGreedy\"],#, \"epsGreedy\"],\n",
    "    \"eps\" : [0.1,0.2,0.3,0.4],#, 0.3, 0.1],\n",
    "    \"delta_time\" : [10,15,20,30,40],\n",
    "    #\"optimizer\": [optimizers.RMSprop(lr= 0.001), optimizers.Adagrad(), optimizers.Adam()]\n",
    "}\n",
    "\n",
    "param_grid = iter_params(**param)\n",
    "\n",
    "\n",
    "\n",
    "def worker(input, output):\n",
    "    \"\"\"Runs through a chunk of the grid\"\"\"\n",
    "\n",
    "    for position, args in iter(input.get, 'STOP'):\n",
    "        result = worker_task(position, args)\n",
    "        output.put(result)\n",
    "\n",
    "\n",
    "def worker_task(position, args):\n",
    "    \"\"\"Tells the worker what to do with grid chunk\"\"\"\n",
    "    # initialise all obje\n",
    "    \n",
    "    # print('Run', position + 1, '-- parameters', args)\n",
    "    \n",
    "    sumo_RL = simulation.simulator(\n",
    "                    connection_label = position + 1,\n",
    "                    q_network_type = 'simple',\n",
    "                    target_q_network_type = 'simple',\n",
    "                    gamma = args[\"gamma\"],\n",
    "                    target_update_freq = args[\"target_update_freq\"],\n",
    "                    train_freq = args[\"train_freq\"],\n",
    "                    num_burn_in = 1000,\n",
    "                    batch_size = args[\"batch_size\"],\n",
    "                    optimizer = optimizers.RMSprop(lr= 0.001),\n",
    "                    loss_func = \"mse\",\n",
    "                    max_ep_length = args[\"max_ep_length\"],\n",
    "                    experiment_id = experiment_id,\n",
    "                    model_checkpoint = True,\n",
    "                    opt_metric = None,\n",
    "\n",
    "                   # environment parameters\n",
    "                    net_file = \"cross.net.xml\",\n",
    "                    route_file = \"cross.rou.xml\",\n",
    "                    demand = \"nominal\",\n",
    "                    state_shape = (1,11),\n",
    "                    num_actions = 2,\n",
    "                    use_gui = False,\n",
    "                    delta_time = args[\"delta_time\"],\n",
    "\n",
    "                   # memory parameters\n",
    "                    max_size = args[\"max_size\"],\n",
    "\n",
    "                   # additional parameters\n",
    "\n",
    "                    policy = args[\"policy\"],\n",
    "                    eps = args[\"eps\"],\n",
    "                    num_episodes = 2,\n",
    "                    monitoring = True,\n",
    "                    episode_recording = False,\n",
    "                    hparams = args.keys())\n",
    "    \n",
    "    # print(\"training agent\", position + 1)\n",
    "    sumo_RL.train()\n",
    "    # print(\"evaluating agent\", position + 1)\n",
    "    evaluation_results = sumo_RL.evaluate(runs = 5)\n",
    "\n",
    "    return (multiprocessing.current_process().name, position + 1, args, evaluation_results[\"unfinished_runs\"],evaluation_results[\"average_delay\"])\n",
    "\n",
    "\n",
    "def gridsearch(param_grid):\n",
    "    \"\"\"Runs a parallelised gridsearch\"\"\"\n",
    "\n",
    "    number_of_processes = multiprocessing.cpu_count()\n",
    "\n",
    "    # Set up task list\n",
    "    tasks = [(idx, val) for idx, val in enumerate(param_grid)]\n",
    "\n",
    "    # Create queues\n",
    "    task_queue = multiprocessing.Queue()\n",
    "    done_queue = multiprocessing.Queue()\n",
    "\n",
    "    # Submit tasks\n",
    "    for task in tasks:\n",
    "        task_queue.put(task)\n",
    "    # Start worker processes\n",
    "    for i in range(number_of_processes):\n",
    "        print('Started process #', i + 1)\n",
    "        multiprocessing.Process(target = worker,\n",
    "                                args = (task_queue, done_queue)).start()\n",
    "      \n",
    "    # Get and print results\n",
    "    results = []\n",
    "    for i in range(len(tasks)):\n",
    "        results.append(done_queue.get())\n",
    "        with open(os.path.join(\"./logs\",exp_id,\"GS_results\"), \"a\",newline='') as file:\n",
    "            writer = csv.writer(file, dialect = 'excel')\n",
    "            writer.writerow(results[-1])                \n",
    "        print('%s -- [RESULTS]: Run %s -- Parameters %s -- Mean duration %6.0f' % results[-1])\n",
    "        \n",
    "    # Tell child processes to stop\n",
    "    for i in range(number_of_processes):\n",
    "        task_queue.put('STOP')\n",
    "\n",
    "    # Now combine the results\n",
    "    scores = [result[-1] for result in results]\n",
    "    lowest = min(scores)\n",
    "    winner = results[scores.index(lowest)]\n",
    "    return winner, results\n",
    "\n",
    "multiprocessing.freeze_support()\n",
    "winner, results = gridsearch(param_grid)\n",
    "winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_test = []\n",
    "eps_test = 0.8\n",
    "for i in range(300000):\n",
    "    eps_test *= omega_test ** i\n",
    "    decay_test.append(eps_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(300000),decay_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_results = pd.DataFrame(results).sort_values(by = 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
